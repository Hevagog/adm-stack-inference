{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d781dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29453b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02515177",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(Path.cwd().parent, 'data', 'stackexchange_dataset.csv')\n",
    "data = pd.read_csv(dataset_path,index_col='question_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80531750",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57409032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>has_accepted_answer</th>\n",
       "      <th>accepted_answer_score</th>\n",
       "      <th>time_to_accepted_answer_hours</th>\n",
       "      <th>question_score</th>\n",
       "      <th>question_text</th>\n",
       "      <th>num_tags</th>\n",
       "      <th>tags</th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>accepted_answer_length_chars</th>\n",
       "      <th>accepted_answer_length_tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79802517</th>\n",
       "      <td>Looking for a better way using &amp;quot;.Include&amp;...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>I am looking for a better way to use the .Incl...</td>\n",
       "      <td>2</td>\n",
       "      <td>['c#', 'entity-framework']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79802934</th>\n",
       "      <td>NTP is moving my clock further from the correc...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Windows 11 Pro 10.0.26200 Build 26200. Dell XP...</td>\n",
       "      <td>1</td>\n",
       "      <td>['ntp']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79802909</th>\n",
       "      <td>Execution of pandas&amp;#39; info in python</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>I am new to pandas library in python. When I l...</td>\n",
       "      <td>2</td>\n",
       "      <td>['python', 'pandas']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79802932</th>\n",
       "      <td>How to debug MongoDB recurring error 314 Objec...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>On a fresh Mongo DB 8.0 mono instance (no clus...</td>\n",
       "      <td>4</td>\n",
       "      <td>['database', 'mongodb', 'nosql', 'system-admin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         title  \\\n",
       "question_id                                                      \n",
       "79802517     Looking for a better way using &quot;.Include&...   \n",
       "79802934     NTP is moving my clock further from the correc...   \n",
       "79802909               Execution of pandas&#39; info in python   \n",
       "79802932     How to debug MongoDB recurring error 314 Objec...   \n",
       "\n",
       "             has_accepted_answer  accepted_answer_score  \\\n",
       "question_id                                               \n",
       "79802517                   False                    NaN   \n",
       "79802934                   False                    NaN   \n",
       "79802909                   False                    NaN   \n",
       "79802932                   False                    NaN   \n",
       "\n",
       "             time_to_accepted_answer_hours  question_score  \\\n",
       "question_id                                                  \n",
       "79802517                               NaN               2   \n",
       "79802934                               NaN               0   \n",
       "79802909                               NaN               0   \n",
       "79802932                               NaN               0   \n",
       "\n",
       "                                                 question_text  num_tags  \\\n",
       "question_id                                                                \n",
       "79802517     I am looking for a better way to use the .Incl...         2   \n",
       "79802934     Windows 11 Pro 10.0.26200 Build 26200. Dell XP...         1   \n",
       "79802909     I am new to pandas library in python. When I l...         2   \n",
       "79802932     On a fresh Mongo DB 8.0 mono instance (no clus...         4   \n",
       "\n",
       "                                                          tags  \\\n",
       "question_id                                                      \n",
       "79802517                            ['c#', 'entity-framework']   \n",
       "79802934                                               ['ntp']   \n",
       "79802909                                  ['python', 'pandas']   \n",
       "79802932     ['database', 'mongodb', 'nosql', 'system-admin...   \n",
       "\n",
       "             accepted_answer_id  accepted_answer_length_chars  \\\n",
       "question_id                                                     \n",
       "79802517                    NaN                           NaN   \n",
       "79802934                    NaN                           NaN   \n",
       "79802909                    NaN                           NaN   \n",
       "79802932                    NaN                           NaN   \n",
       "\n",
       "             accepted_answer_length_tokens  \n",
       "question_id                                 \n",
       "79802517                               NaN  \n",
       "79802934                               NaN  \n",
       "79802909                               NaN  \n",
       "79802932                               NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc92aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_embedding = data[['title','question_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca6c4961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79802517</th>\n",
       "      <td>Looking for a better way using &amp;quot;.Include&amp;...</td>\n",
       "      <td>I am looking for a better way to use the .Incl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79802934</th>\n",
       "      <td>NTP is moving my clock further from the correc...</td>\n",
       "      <td>Windows 11 Pro 10.0.26200 Build 26200. Dell XP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79802909</th>\n",
       "      <td>Execution of pandas&amp;#39; info in python</td>\n",
       "      <td>I am new to pandas library in python. When I l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79802932</th>\n",
       "      <td>How to debug MongoDB recurring error 314 Objec...</td>\n",
       "      <td>On a fresh Mongo DB 8.0 mono instance (no clus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79802919</th>\n",
       "      <td>How to integrate QML UI into a custom Vulkan r...</td>\n",
       "      <td>I'm developing a custom Vulkan renderer and wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79662126</th>\n",
       "      <td>Is there a built-in identity function in JavaS...</td>\n",
       "      <td>Is there a function in JavaScript that accepts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79662912</th>\n",
       "      <td>How can I improve the accuracy of my Transform...</td>\n",
       "      <td>I'm training a Transformer-based text classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79663172</th>\n",
       "      <td>How to get a clickable PDF in HTML</td>\n",
       "      <td>To have a picture (eg. in jpg format) on a web...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79659655</th>\n",
       "      <td>Unable to start debugging. Unexpected GDB outp...</td>\n",
       "      <td>On a pristine new Windows 11, installed Visual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17945108</th>\n",
       "      <td>Selenium RC: &amp;quot;waiting for window &amp;#39;nul...</td>\n",
       "      <td>I am totally at a loss here, trying to run a m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99992 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         title  \\\n",
       "question_id                                                      \n",
       "79802517     Looking for a better way using &quot;.Include&...   \n",
       "79802934     NTP is moving my clock further from the correc...   \n",
       "79802909               Execution of pandas&#39; info in python   \n",
       "79802932     How to debug MongoDB recurring error 314 Objec...   \n",
       "79802919     How to integrate QML UI into a custom Vulkan r...   \n",
       "...                                                        ...   \n",
       "79662126     Is there a built-in identity function in JavaS...   \n",
       "79662912     How can I improve the accuracy of my Transform...   \n",
       "79663172                    How to get a clickable PDF in HTML   \n",
       "79659655     Unable to start debugging. Unexpected GDB outp...   \n",
       "17945108     Selenium RC: &quot;waiting for window &#39;nul...   \n",
       "\n",
       "                                                 question_text  \n",
       "question_id                                                     \n",
       "79802517     I am looking for a better way to use the .Incl...  \n",
       "79802934     Windows 11 Pro 10.0.26200 Build 26200. Dell XP...  \n",
       "79802909     I am new to pandas library in python. When I l...  \n",
       "79802932     On a fresh Mongo DB 8.0 mono instance (no clus...  \n",
       "79802919     I'm developing a custom Vulkan renderer and wa...  \n",
       "...                                                        ...  \n",
       "79662126     Is there a function in JavaScript that accepts...  \n",
       "79662912     I'm training a Transformer-based text classifi...  \n",
       "79663172     To have a picture (eg. in jpg format) on a web...  \n",
       "79659655     On a pristine new Windows 11, installed Visual...  \n",
       "17945108     I am totally at a loss here, trying to run a m...  \n",
       "\n",
       "[99992 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054cffa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ea27841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "BATCH_SIZE = 100\n",
    "model = 'qwen3-embedding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a5ef0f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total texts to embed: 199984\n"
     ]
    }
   ],
   "source": [
    "texts_to_embed = data_for_embedding['title'].tolist() + data_for_embedding['question_text'].tolist()\n",
    "print(f\"Total texts to embed: {len(texts_to_embed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "44ec163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7e4c9360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [6:06:48<00:00, 11.00s/it]  \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, len(texts_to_embed), BATCH_SIZE)):\n",
    "    batch_texts = texts_to_embed[i:i + BATCH_SIZE]\n",
    "    result = ollama.embed(\n",
    "            model=model,\n",
    "            input=batch_texts\n",
    "        )\n",
    "    batch_embeddings = [np.array(e) for e in result['embeddings']]\n",
    "    all_embeddings.extend(batch_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "57b2ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = len(data_for_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c9cfb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_embeddings = all_embeddings[0:num_rows]\n",
    "question_text_embeddings = all_embeddings[num_rows:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "73979025",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings = pd.DataFrame(\n",
    "    {\n",
    "        'title_embedding': title_embeddings,\n",
    "        'question_text_embedding': question_text_embeddings\n",
    "    },\n",
    "    index=data_for_embedding.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "98c700bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_embedding</th>\n",
       "      <th>question_text_embedding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79802517</th>\n",
       "      <td>[0.008553513, -0.009437113, 0.009673767, -0.02...</td>\n",
       "      <td>[0.0013518566, -0.015674047, -0.004076924, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79802934</th>\n",
       "      <td>[0.019479005, 0.007850029, -0.020600174, -0.02...</td>\n",
       "      <td>[0.009473968, -0.014583107, -0.019139914, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79802909</th>\n",
       "      <td>[-0.01977205, 0.0042978777, -0.03637585, -0.01...</td>\n",
       "      <td>[-0.0019663926, -0.024625326, -0.027527379, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79802932</th>\n",
       "      <td>[0.020906445, -0.010505062, 0.0033248097, -0.0...</td>\n",
       "      <td>[0.0403566, -0.016648613, 0.0031766212, -0.001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title_embedding  \\\n",
       "question_id                                                      \n",
       "79802517     [0.008553513, -0.009437113, 0.009673767, -0.02...   \n",
       "79802934     [0.019479005, 0.007850029, -0.020600174, -0.02...   \n",
       "79802909     [-0.01977205, 0.0042978777, -0.03637585, -0.01...   \n",
       "79802932     [0.020906445, -0.010505062, 0.0033248097, -0.0...   \n",
       "\n",
       "                                       question_text_embedding  \n",
       "question_id                                                     \n",
       "79802517     [0.0013518566, -0.015674047, -0.004076924, -0....  \n",
       "79802934     [0.009473968, -0.014583107, -0.019139914, 0.00...  \n",
       "79802909     [-0.0019663926, -0.024625326, -0.027527379, -0...  \n",
       "79802932     [0.0403566, -0.016648613, 0.0031766212, -0.001...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embeddings.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "048da759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings.to_pickle(os.path.join(Path.cwd().parent, 'data', 'stackexchange_embeddings.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e4d8cb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_embedding</th>\n",
       "      <th>question_text_embedding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79802517</th>\n",
       "      <td>[0.008553513, -0.009437113, 0.009673767, -0.02...</td>\n",
       "      <td>[0.0013518566, -0.015674047, -0.004076924, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79802934</th>\n",
       "      <td>[0.019479005, 0.007850029, -0.020600174, -0.02...</td>\n",
       "      <td>[0.009473968, -0.014583107, -0.019139914, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79802909</th>\n",
       "      <td>[-0.01977205, 0.0042978777, -0.03637585, -0.01...</td>\n",
       "      <td>[-0.0019663926, -0.024625326, -0.027527379, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79802932</th>\n",
       "      <td>[0.020906445, -0.010505062, 0.0033248097, -0.0...</td>\n",
       "      <td>[0.0403566, -0.016648613, 0.0031766212, -0.001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title_embedding  \\\n",
       "question_id                                                      \n",
       "79802517     [0.008553513, -0.009437113, 0.009673767, -0.02...   \n",
       "79802934     [0.019479005, 0.007850029, -0.020600174, -0.02...   \n",
       "79802909     [-0.01977205, 0.0042978777, -0.03637585, -0.01...   \n",
       "79802932     [0.020906445, -0.010505062, 0.0033248097, -0.0...   \n",
       "\n",
       "                                       question_text_embedding  \n",
       "question_id                                                     \n",
       "79802517     [0.0013518566, -0.015674047, -0.004076924, -0....  \n",
       "79802934     [0.009473968, -0.014583107, -0.019139914, 0.00...  \n",
       "79802909     [-0.0019663926, -0.024625326, -0.027527379, -0...  \n",
       "79802932     [0.0403566, -0.016648613, 0.0031766212, -0.001...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embeddings.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8a84e96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embeddings.iloc[0]['title_embedding'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b40e2b4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error converting column \"title_embedding\" to bytes using encoding JSON. Original error: Object of type ndarray is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studies/advanced-data-mining/.venv/lib/python3.13/site-packages/fastparquet/writer.py:275\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(data, se)\u001b[39m\n\u001b[32m    273\u001b[39m     \u001b[38;5;66;03m# TODO: avoid list. np.fromiter can be used with numpy >= 1.23.0,\u001b[39;00m\n\u001b[32m    274\u001b[39m     \u001b[38;5;66;03m#  but older versions don't support object arrays.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m     out = np.array([\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data], dtype=\u001b[33m\"\u001b[39m\u001b[33mO\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m converted_type == parquet_thrift.ConvertedType.BSON:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studies/advanced-data-mining/.venv/lib/python3.13/site-packages/fastparquet/json.py:78\u001b[39m, in \u001b[36mJsonImpl.dumps\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdumps\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.encode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/json/__init__.py:238\u001b[39m, in \u001b[36mdumps\u001b[39m\u001b[34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONEncoder\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/json/encoder.py:200\u001b[39m, in \u001b[36mJSONEncoder.encode\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/json/encoder.py:261\u001b[39m, in \u001b[36mJSONEncoder.iterencode\u001b[39m\u001b[34m(self, o, _one_shot)\u001b[39m\n\u001b[32m    257\u001b[39m     _iterencode = _make_iterencode(\n\u001b[32m    258\u001b[39m         markers, \u001b[38;5;28mself\u001b[39m.default, _encoder, indent, floatstr,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mself\u001b[39m.key_separator, \u001b[38;5;28mself\u001b[39m.item_separator, \u001b[38;5;28mself\u001b[39m.sort_keys,\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m.skipkeys, _one_shot)\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/json/encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03ma serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m(to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type ndarray is not JSON serializable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_embeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstackexchange_embeddings.parquet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfastparquet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_encoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mjson\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studies/advanced-data-mining/.venv/lib/python3.13/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studies/advanced-data-mining/.venv/lib/python3.13/site-packages/pandas/core/frame.py:3124\u001b[39m, in \u001b[36mDataFrame.to_parquet\u001b[39m\u001b[34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[39m\n\u001b[32m   3043\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3044\u001b[39m \u001b[33;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[32m   3045\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3120\u001b[39m \u001b[33;03m>>> content = f.read()\u001b[39;00m\n\u001b[32m   3121\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3122\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[32m-> \u001b[39m\u001b[32m3124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3125\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3132\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3133\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studies/advanced-data-mining/.venv/lib/python3.13/site-packages/pandas/io/parquet.py:482\u001b[39m, in \u001b[36mto_parquet\u001b[39m\u001b[34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m impl = get_engine(engine)\n\u001b[32m    480\u001b[39m path_or_buf: FilePath | WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] = io.BytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, io.BytesIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studies/advanced-data-mining/.venv/lib/python3.13/site-packages/pandas/io/parquet.py:351\u001b[39m, in \u001b[36mFastParquetImpl.write\u001b[39m\u001b[34m(self, df, path, compression, index, partition_cols, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    346\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    347\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstorage_options passed with file object or non-fsspec file path\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    348\u001b[39m     )\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m catch_warnings(record=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwrite_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpartition_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studies/advanced-data-mining/.venv/lib/python3.13/site-packages/fastparquet/writer.py:1343\u001b[39m, in \u001b[36mwrite\u001b[39m\u001b[34m(filename, data, row_group_offsets, compression, file_scheme, open_with, mkdirs, has_nulls, write_index, partition_on, fixed_text, append, object_encoding, times, custom_metadata, stats)\u001b[39m\n\u001b[32m   1339\u001b[39m     fmd.key_value_metadata = kvm\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file_scheme == \u001b[33m'\u001b[39m\u001b[33msimple\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m   1342\u001b[39m     \u001b[38;5;66;03m# Case 'simple'\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1343\u001b[39m     \u001b[43mwrite_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mrow_group_offsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow_group_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopen_with\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopen_with\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mhas_nulls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1348\u001b[39m     \u001b[38;5;66;03m# Case 'hive', 'drill'\u001b[39;00m\n\u001b[32m   1349\u001b[39m     write_multi(filename, data, fmd,\n\u001b[32m   1350\u001b[39m                 row_group_offsets=row_group_offsets,\n\u001b[32m   1351\u001b[39m                 compression=compression, file_scheme=file_scheme,\n\u001b[32m   1352\u001b[39m                 write_fmd=\u001b[38;5;28;01mTrue\u001b[39;00m, open_with=open_with,\n\u001b[32m   1353\u001b[39m                 mkdirs=mkdirs, partition_on=partition_on,\n\u001b[32m   1354\u001b[39m                 append=\u001b[38;5;28;01mFalse\u001b[39;00m, stats=stats)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studies/advanced-data-mining/.venv/lib/python3.13/site-packages/fastparquet/writer.py:1004\u001b[39m, in \u001b[36mwrite_simple\u001b[39m\u001b[34m(fn, data, fmd, row_group_offsets, compression, open_with, has_nulls, append, stats)\u001b[39m\n\u001b[32m   1002\u001b[39m of = open_with(fn, mode)\n\u001b[32m   1003\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m of \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m-> \u001b[39m\u001b[32m1004\u001b[39m     \u001b[43mwrite_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studies/advanced-data-mining/.venv/lib/python3.13/site-packages/fastparquet/writer.py:988\u001b[39m, in \u001b[36mwrite_simple.<locals>.write_to_file\u001b[39m\u001b[34m(f)\u001b[39m\n\u001b[32m    986\u001b[39m rgs = fmd.row_groups\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, row_group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data):\n\u001b[32m--> \u001b[39m\u001b[32m988\u001b[39m     rg = \u001b[43mmake_row_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    990\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m rg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    991\u001b[39m         rgs.append(rg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studies/advanced-data-mining/.venv/lib/python3.13/site-packages/fastparquet/writer.py:805\u001b[39m, in \u001b[36mmake_row_group\u001b[39m\u001b[34m(f, data, schema, compression, stats)\u001b[39m\n\u001b[32m    803\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    804\u001b[39m             st = column.name \u001b[38;5;129;01min\u001b[39;00m stats\n\u001b[32m--> \u001b[39m\u001b[32m805\u001b[39m         chunk = \u001b[43mwrite_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoldata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    807\u001b[39m         cols.append(chunk)\n\u001b[32m    808\u001b[39m rg = ThriftObject.from_fields(\n\u001b[32m    809\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRowGroup\u001b[39m\u001b[33m\"\u001b[39m, num_rows=rows, columns=cols,\n\u001b[32m    810\u001b[39m     total_byte_size=\u001b[38;5;28msum\u001b[39m([c.meta_data.total_uncompressed_size \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cols]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studies/advanced-data-mining/.venv/lib/python3.13/site-packages/fastparquet/writer.py:638\u001b[39m, in \u001b[36mwrite_column\u001b[39m\u001b[34m(f, data0, selement, compression, datapage_version, stats)\u001b[39m\n\u001b[32m    634\u001b[39m     data = data.astype(\u001b[33m'\u001b[39m\u001b[33mint32\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    636\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datapage_version == \u001b[32m1\u001b[39m:\n\u001b[32m    637\u001b[39m     bdata = \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join([\n\u001b[32m--> \u001b[39m\u001b[32m638\u001b[39m         repetition_data, definition_data, \u001b[43mencode\u001b[49m\u001b[43m[\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselement\u001b[49m\u001b[43m)\u001b[49m, \u001b[32m8\u001b[39m * \u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\x00\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    639\u001b[39m     ])\n\u001b[32m    640\u001b[39m     dph = parquet_thrift.DataPageHeader(\n\u001b[32m    641\u001b[39m         num_values=check_32(row_end - row_start),\n\u001b[32m    642\u001b[39m         encoding=\u001b[38;5;28mgetattr\u001b[39m(parquet_thrift.Encoding, encoding),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         i32=\u001b[32m1\u001b[39m\n\u001b[32m    646\u001b[39m     )\n\u001b[32m    647\u001b[39m     l0 = \u001b[38;5;28mlen\u001b[39m(bdata)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studies/advanced-data-mining/.venv/lib/python3.13/site-packages/fastparquet/writer.py:391\u001b[39m, in \u001b[36mencode_plain\u001b[39m\u001b[34m(data, se)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode_plain\u001b[39m(data, se):\n\u001b[32m    390\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"PLAIN encoding; returns byte representation\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m     out = \u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m se.type == parquet_thrift.Type.BYTE_ARRAY:\n\u001b[32m    393\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m pack_byte_array(\u001b[38;5;28mlist\u001b[39m(out))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studies/advanced-data-mining/.venv/lib/python3.13/site-packages/fastparquet/writer.py:283\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(data, se)\u001b[39m\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    281\u001b[39m         ct = parquet_thrift.ConvertedType._VALUES_TO_NAMES[\n\u001b[32m    282\u001b[39m             converted_type] \u001b[38;5;28;01mif\u001b[39;00m converted_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mError converting column \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m to bytes using \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    284\u001b[39m                          \u001b[33m'\u001b[39m\u001b[33mencoding \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m. Original error: \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    285\u001b[39m                          \u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m % (data.name, ct, e))\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mstr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(dtype):\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Error converting column \"title_embedding\" to bytes using encoding JSON. Original error: Object of type ndarray is not JSON serializable"
     ]
    }
   ],
   "source": [
    "df_embeddings.to_parquet(os.path.join(Path.cwd().parent, 'data', 'stackexchange_embeddings.parquet'), engine='fastparquet', object_encoding='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cff381",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings.to_csv(os.path.join(Path.cwd().parent, 'data', 'stackexchange_embeddings.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a5eefecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_embeddings_array = np.stack(df_embeddings['title_embedding'].values)\n",
    "question_embeddings_array = np.stack(df_embeddings['question_text_embedding'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "23e181c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((99992, 4096), (99992, 4096))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_embeddings_array.shape, question_embeddings_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1034ea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(Path.cwd().parent, 'data')\n",
    "title_path = os.path.join(output_dir, 'title_embeddings.npy')\n",
    "question_path = os.path.join(output_dir, 'question_embeddings.npy')\n",
    "np.save(title_path, title_embeddings_array)\n",
    "np.save(question_path, question_embeddings_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1b7b3a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "15071049",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50, random_state=42)\n",
    "X_pca = pca.fit_transform(title_embeddings_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f866afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2000\n",
    "kmeans = KMeans(n_clusters=K, random_state=42, n_init='auto')\n",
    "cluster_labels = kmeans.fit_predict(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "95543b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calinski-Harabasz Index (K=2000): 86.23\n"
     ]
    }
   ],
   "source": [
    "ch_score = calinski_harabasz_score(X_pca, cluster_labels)\n",
    "\n",
    "print(f\"Calinski-Harabasz Index (K={K}): {ch_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6f73fbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calinski-Harabasz Index (K=10): 2949.47\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "kmeans = KMeans(n_clusters=K, random_state=42, n_init='auto')\n",
    "cluster_labels = kmeans.fit_predict(X_pca)\n",
    "ch_score = calinski_harabasz_score(X_pca, cluster_labels)\n",
    "\n",
    "print(f\"Calinski-Harabasz Index (K={K}): {ch_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f2d8c23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calinski-Harabasz Index (K=2137): 82.12\n"
     ]
    }
   ],
   "source": [
    "K = 2137\n",
    "kmeans = KMeans(n_clusters=K, random_state=42, n_init='auto')\n",
    "cluster_labels = kmeans.fit_predict(X_pca)\n",
    "ch_score = calinski_harabasz_score(X_pca, cluster_labels)\n",
    "\n",
    "print(f\"Calinski-Harabasz Index (K={K}): {ch_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "aa9dad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_data = title_embeddings_array - np.mean(title_embeddings_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "403aae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_variance = np.trace(np.cov(centered_data, rowvar=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7acd7099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6058743982434113)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_variance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
