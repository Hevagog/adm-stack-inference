{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddbc105d",
   "metadata": {},
   "source": [
    "# StackOverflow Score Prediction – Advanced Models (Notebook 2)\n",
    "\n",
    "This companion notebook extends the baseline TF-IDF experiments by layering more expressive regressors, dimensionality reduction, neural nets, document embeddings, and light ensembling while keeping the original preprocessing and data splits intact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2013e6d3",
   "metadata": {},
   "source": [
    "## Load Data & Reuse Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48fbd3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data file: C:\\Users\\tomasz.makowski.2\\Desktop\\SemesterII\\AdvancedDataMining\\adm-stack-inference\\data\\stackexchange_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List\n",
    "\n",
    "import gensim.downloader as gensim_api\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from nltk import download as nltk_download\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge, SGDRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if not (PROJECT_ROOT / \"data\").exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "NOTEBOOKS_DIR = PROJECT_ROOT / \"notebooks\"\n",
    "for path in {PROJECT_ROOT, NOTEBOOKS_DIR}:\n",
    "    path_str = str(path)\n",
    "    if path_str not in sys.path:\n",
    "        sys.path.append(path_str)\n",
    "\n",
    "from notebooks.algorithms.text_utils import (\n",
    "    preprocess_text,\n",
    "    tokens_to_text,\n",
    ")\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "pd.set_option(\"display.max_colwidth\", 120)\n",
    "RANDOM_STATE = 42\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"stackexchange_dataset.csv\"\n",
    "print(f\"Using data file: {DATA_PATH}\")\n",
    "from time import perf_counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2456fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw rows: 100,000\n",
      "Filtered rows: 99,992\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>num_tags</th>\n",
       "      <th>tags</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79802517</td>\n",
       "      <td>Looking for a better way using &amp;quot;.Include&amp;quot; in EF</td>\n",
       "      <td>I am looking for a better way to use the .Include clause of Entity Framework. I want to avoid duplicate code. I have...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>['c#', 'entity-framework']</td>\n",
       "      <td>Looking for a better way using &amp;quot;.Include&amp;quot; in EF I am looking for a better way to use the .Include clause o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79802934</td>\n",
       "      <td>NTP is moving my clock further from the correct time, rather than closer</td>\n",
       "      <td>Windows 11 Pro 10.0.26200 Build 26200. Dell XPS 8940. When I first started noticing it, a few weeks ago, my clock wa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['ntp']</td>\n",
       "      <td>NTP is moving my clock further from the correct time, rather than closer Windows 11 Pro 10.0.26200 Build 26200. Dell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79802909</td>\n",
       "      <td>Execution of pandas&amp;#39; info in python</td>\n",
       "      <td>I am new to pandas library in python. When I loaded a file and was printing the output of df.info into console, the ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>['python', 'pandas']</td>\n",
       "      <td>Execution of pandas&amp;#39; info in python I am new to pandas library in python. When I loaded a file and was printing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id  \\\n",
       "0     79802517   \n",
       "1     79802934   \n",
       "2     79802909   \n",
       "\n",
       "                                                                      title  \\\n",
       "0                 Looking for a better way using &quot;.Include&quot; in EF   \n",
       "1  NTP is moving my clock further from the correct time, rather than closer   \n",
       "2                                   Execution of pandas&#39; info in python   \n",
       "\n",
       "                                                                                                                      body  \\\n",
       "0  I am looking for a better way to use the .Include clause of Entity Framework. I want to avoid duplicate code. I have...   \n",
       "1  Windows 11 Pro 10.0.26200 Build 26200. Dell XPS 8940. When I first started noticing it, a few weeks ago, my clock wa...   \n",
       "2  I am new to pandas library in python. When I loaded a file and was printing the output of df.info into console, the ...   \n",
       "\n",
       "   score  num_tags                        tags  \\\n",
       "0    2.0         2  ['c#', 'entity-framework']   \n",
       "1    0.0         1                     ['ntp']   \n",
       "2    0.0         2        ['python', 'pandas']   \n",
       "\n",
       "                                                                                                                 full_text  \n",
       "0  Looking for a better way using &quot;.Include&quot; in EF I am looking for a better way to use the .Include clause o...  \n",
       "1  NTP is moving my clock further from the correct time, rather than closer Windows 11 Pro 10.0.26200 Build 26200. Dell...  \n",
       "2  Execution of pandas&#39; info in python I am new to pandas library in python. When I loaded a file and was printing ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Raw rows: {len(raw_df):,}\")\n",
    "\n",
    "df = (\n",
    "    raw_df.rename(columns={\"question_text\": \"body\", \"question_score\": \"score\"})[\n",
    "        [\"question_id\", \"title\", \"body\", \"score\", \"num_tags\", \"tags\"]\n",
    "    ]\n",
    "    .dropna(subset=[\"title\", \"body\", \"score\"])\n",
    "    .copy()\n",
    ")\n",
    "df[\"score\"] = pd.to_numeric(df[\"score\"], errors=\"coerce\")\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna(subset=[\"score\"])\n",
    "df[\"score\"] = df[\"score\"].astype(float)\n",
    "df[\"title\"] = df[\"title\"].fillna(\"\").astype(str)\n",
    "df[\"body\"] = df[\"body\"].fillna(\"\").astype(str)\n",
    "df[\"full_text\"] = (df[\"title\"].str.strip() + \" \" + df[\"body\"].str.strip()).str.strip()\n",
    "df = df[df[\"full_text\"].str.len() > 0]\n",
    "print(f\"Filtered rows: {len(df):,}\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c4099d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   score  \\\n",
      "0    2.0   \n",
      "1    0.0   \n",
      "2    0.0   \n",
      "\n",
      "                                                                                                                clean_text  \n",
      "0  looking better way using quot include quot ef looking better way use include clause entity framework want avoid dupl...  \n",
      "1  ntp moving clock correct time rather closer windows 11 pro 10 0 26200 build 26200 dell xps 8940 first started notici...  \n",
      "2  execution pandas #39 info python new pandas library python loaded file printing output df info console data getting ...  \n"
     ]
    }
   ],
   "source": [
    "nltk_download('stopwords', quiet=True)\n",
    "stopword_list = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "normalized_texts: List[str] = []\n",
    "clean_texts: List[str] = []\n",
    "for text in df[\"full_text\"]:\n",
    "    normalized, tokens = preprocess_text(text, stopword_list, stemmer=None)\n",
    "    normalized_texts.append(normalized)\n",
    "    clean_texts.append(tokens_to_text(tokens))\n",
    "\n",
    "df[\"normalized_text\"] = normalized_texts\n",
    "df[\"clean_text\"] = clean_texts\n",
    "print(df[[\"score\", \"clean_text\"]].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "450e5275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes: train=69,994, val=14,999, test=14,999\n"
     ]
    }
   ],
   "source": [
    "train_df, temp_df = train_test_split(\n",
    "    df, test_size=0.30, random_state=RANDOM_STATE\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.50, random_state=RANDOM_STATE\n",
    ")\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "train_val_df = pd.concat([train_df, val_df], axis=0, ignore_index=True)\n",
    "\n",
    "y_train = train_df[\"score\"].values\n",
    "y_val = val_df[\"score\"].values\n",
    "y_test = test_df[\"score\"].values\n",
    "y_train_val = train_val_df[\"score\"].values\n",
    "\n",
    "print(f\"Split sizes: train={len(train_df):,}, val={len(val_df):,}, test={len(test_df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f95a5cd",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer (Reused Settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e75241b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shapes: {'train': (69994, 42114), 'val': (14999, 42114), 'test': (14999, 42114), 'train_val': (84993, 42114)}\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.85, ngram_range=(1, 1))\n",
    "X_train_tfidf = vectorizer.fit_transform(train_df[\"clean_text\"])\n",
    "X_val_tfidf = vectorizer.transform(val_df[\"clean_text\"])\n",
    "X_test_tfidf = vectorizer.transform(test_df[\"clean_text\"])\n",
    "X_train_val_tfidf = vectorizer.transform(train_val_df[\"clean_text\"])\n",
    "\n",
    "feature_store: Dict[str, Dict[str, object]] = {\n",
    "    \"tfidf\": {\n",
    "        \"train\": X_train_tfidf,\n",
    "        \"val\": X_val_tfidf,\n",
    "        \"test\": X_test_tfidf,\n",
    "        \"train_val\": X_train_val_tfidf,\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"TF-IDF shapes:\", {k: v.shape for k, v in feature_store[\"tfidf\"].items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714a1af0",
   "metadata": {},
   "source": [
    "## Target Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d00bfe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw target range: (np.float64(-20.0), np.float64(27126.0))\n",
      "Log target range: (np.float64(-6.907755278982136), np.float64(10.20828482084353))\n"
     ]
    }
   ],
   "source": [
    "LOG_SCORE_CLIP_MIN = -0.999\n",
    "LOG_PRED_CLIP = 6.0\n",
    "y_log_train = np.log1p(np.clip(y_train, a_min=LOG_SCORE_CLIP_MIN, a_max=None))\n",
    "y_log_val = np.log1p(np.clip(y_val, a_min=LOG_SCORE_CLIP_MIN, a_max=None))\n",
    "y_log_test = np.log1p(np.clip(y_test, a_min=LOG_SCORE_CLIP_MIN, a_max=None))\n",
    "y_log_train_val = np.log1p(np.clip(y_train_val, a_min=LOG_SCORE_CLIP_MIN, a_max=None))\n",
    "\n",
    "target_store: Dict[str, Dict[str, np.ndarray]] = {\n",
    "    \"raw\": {\n",
    "        \"train\": y_train,\n",
    "        \"val\": y_val,\n",
    "        \"test\": y_test,\n",
    "        \"train_val\": y_train_val,\n",
    "    },\n",
    "    \"log\": {\n",
    "        \"train\": y_log_train,\n",
    "        \"val\": y_log_val,\n",
    "        \"test\": y_log_test,\n",
    "        \"train_val\": y_log_train_val,\n",
    "    },\n",
    "}\n",
    "print(\"Raw target range:\", (y_train.min(), y_train.max()))\n",
    "print(\"Log target range:\", (y_log_train.min(), y_log_train.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba137c85",
   "metadata": {},
   "source": [
    "## Helper Functions & Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "544f06d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {\"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae, \"R2\": r2}\n",
    "\n",
    "results: List[Dict[str, object]] = []\n",
    "model_registry: Dict[str, Dict[str, object]] = {}\n",
    "val_predictions_store: Dict[str, np.ndarray] = {}\n",
    "\n",
    "TARGET_DESCRIPTIONS = {\"raw\": \"raw score\", \"log\": \"log1p(score)\"}\n",
    "\n",
    "def inverse_target(key: str, preds: np.ndarray) -> np.ndarray:\n",
    "    if key == \"log\":\n",
    "        clipped = np.clip(preds, a_min=LOG_SCORE_CLIP_MIN, a_max=LOG_PRED_CLIP)\n",
    "        return np.expm1(clipped)\n",
    "    return preds\n",
    "\n",
    "def register_result(name: str, feature_type: str, target_key: str, metrics: Dict[str, float], notes: str = \"\", training_time: float | None = None):\n",
    "    entry = {\n",
    "        \"model_name\": name,\n",
    "        \"feature_type\": feature_type,\n",
    "        \"target_type\": TARGET_DESCRIPTIONS[target_key],\n",
    "        \"val_MSE\": metrics[\"MSE\"],\n",
    "        \"val_RMSE\": metrics[\"RMSE\"],\n",
    "        \"val_MAE\": metrics[\"MAE\"],\n",
    "        \"val_R2\": metrics[\"R2\"],\n",
    "        \"training_time_sec\": training_time,\n",
    "        \"notes\": notes,\n",
    "    }\n",
    "    results.append(entry)\n",
    "\n",
    "def evaluate_model(name: str, feature_key: str, target_key: str, builder: Callable[[], object], feature_type: str, notes: str = \"\"):\n",
    "    model = builder()\n",
    "    X_train = feature_store[feature_key][\"train\"]\n",
    "    X_val = feature_store[feature_key][\"val\"]\n",
    "    y_train_local = target_store[target_key][\"train\"]\n",
    "    start = perf_counter()\n",
    "    model.fit(X_train, y_train_local)\n",
    "    training_time = perf_counter() - start\n",
    "    val_preds_target = model.predict(X_val)\n",
    "    val_preds = inverse_target(target_key, val_preds_target)\n",
    "    val_preds = np.nan_to_num(val_preds, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    metrics = regression_metrics(y_val, val_preds)\n",
    "    register_result(name, feature_type, target_key, metrics, notes, training_time=training_time)\n",
    "    model_registry[name] = {\n",
    "        \"builder\": builder,\n",
    "        \"feature_key\": feature_key,\n",
    "        \"target_key\": target_key,\n",
    "        \"feature_type\": feature_type,\n",
    "        \"notes\": notes,\n",
    "    }\n",
    "    val_predictions_store[name] = val_preds\n",
    "    print(f\"{name}: RMSE={metrics['RMSE']:.3f}, R2={metrics['R2']:.3f}, train_time={training_time:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cf9a39",
   "metadata": {},
   "source": [
    "## LinearSVR on TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7d55cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_linear_svr(C: float = 1.0):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),\n",
    "        (\"svr\", LinearSVR(C=C, epsilon=0.1, random_state=RANDOM_STATE, max_iter=5000, tol=1e-4)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dcb483b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVR (raw): RMSE=158.358, R2=-0.046, train_time=138.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomasz.makowski.2\\Desktop\\SemesterII\\AdvancedDataMining\\adm-stack-inference\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Raw target\n",
    "evaluate_model(\n",
    "    name=\"LinearSVR (raw)\",\n",
    "    feature_key=\"tfidf\",\n",
    "    target_key=\"raw\",\n",
    "    builder=lambda: build_linear_svr(C=0.8),\n",
    "    feature_type=\"TF-IDF (sparse)\",\n",
    "    notes=\"LinearSVR predicting raw scores\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "012ce745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVR (log): RMSE=184.963, R2=-0.427, train_time=179.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomasz.makowski.2\\Desktop\\SemesterII\\AdvancedDataMining\\adm-stack-inference\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Log target\n",
    "evaluate_model(\n",
    "    name=\"LinearSVR (log)\",\n",
    "    feature_key=\"tfidf\",\n",
    "    target_key=\"log\",\n",
    "    builder=lambda: build_linear_svr(C=0.8),\n",
    "    feature_type=\"TF-IDF (sparse)\",\n",
    "    notes=\"LinearSVR trained on log1p scores\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb30c520",
   "metadata": {},
   "source": [
    "## SGDRegressor with Huber Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca85f42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_huber_sgd(alpha: float = 1e-4):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),\n",
    "        (\"sgd\", SGDRegressor(\n",
    "            loss=\"huber\",\n",
    "            epsilon=1.5,\n",
    "            penalty=\"l2\",\n",
    "            alpha=alpha,\n",
    "            learning_rate=\"optimal\",\n",
    "            max_iter=5000,\n",
    "            tol=1e-3,\n",
    "            random_state=RANDOM_STATE,\n",
    "        )),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6cd868a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Huber (raw): RMSE=157.950, R2=-0.041, train_time=28.66s\n"
     ]
    }
   ],
   "source": [
    "# Raw target\n",
    "evaluate_model(\n",
    "    name=\"SGD Huber (raw)\",\n",
    "    feature_key=\"tfidf\",\n",
    "    target_key=\"raw\",\n",
    "    builder=lambda: build_huber_sgd(alpha=1e-4),\n",
    "    feature_type=\"TF-IDF (sparse)\",\n",
    "    notes=\"Huber regression with SGD on raw scores\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbe329ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Huber (log): RMSE=265.615, R2=-1.944, train_time=26.37s\n"
     ]
    }
   ],
   "source": [
    "# Log target\n",
    "evaluate_model(\n",
    "    name=\"SGD Huber (log)\",\n",
    "    feature_key=\"tfidf\",\n",
    "    target_key=\"log\",\n",
    "    builder=lambda: build_huber_sgd(alpha=5e-5),\n",
    "    feature_type=\"TF-IDF (sparse)\",\n",
    "    notes=\"Huber regression with SGD on log scores\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4362c6",
   "metadata": {},
   "source": [
    "## TF-IDF → TruncatedSVD → Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2f8372b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD shapes: {'train': (69994, 200), 'val': (14999, 200), 'test': (14999, 200), 'train_val': (84993, 200)}\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=200, random_state=RANDOM_STATE)\n",
    "X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "X_val_svd = svd.transform(X_val_tfidf)\n",
    "X_test_svd = svd.transform(X_test_tfidf)\n",
    "X_train_val_svd = svd.transform(X_train_val_tfidf)\n",
    "\n",
    "feature_store[\"svd\"] = {\n",
    "    \"train\": X_train_svd,\n",
    "    \"val\": X_val_svd,\n",
    "    \"test\": X_test_svd,\n",
    "    \"train_val\": X_train_val_svd,\n",
    "}\n",
    "print(\"SVD shapes:\", {k: v.shape for k, v in feature_store[\"svd\"].items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "560f182b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD + Ridge: RMSE=152.392, R2=0.031, train_time=0.25s\n"
     ]
    }
   ],
   "source": [
    "def build_svd_ridge(alpha: float = 2.0):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"ridge\", Ridge(alpha=alpha, random_state=RANDOM_STATE)),\n",
    "    ])\n",
    "\n",
    "# Ridge\n",
    "evaluate_model(\n",
    "    name=\"SVD + Ridge\",\n",
    "    feature_key=\"svd\",\n",
    "    target_key=\"raw\",\n",
    "    builder=lambda: build_svd_ridge(alpha=2.0),\n",
    "    feature_type=\"TF-IDF → 200-d SVD\",\n",
    "    notes=\"Dense LSA features with Ridge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7f80f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD + RandomForest: RMSE=154.977, R2=-0.002, train_time=1316.23s\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "def build_rf():\n",
    "    return RandomForestRegressor(\n",
    "        n_estimators=400,\n",
    "        max_depth=14,\n",
    "        min_samples_leaf=2,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "evaluate_model(\n",
    "    name=\"SVD + RandomForest\",\n",
    "    feature_key=\"svd\",\n",
    "    target_key=\"raw\",\n",
    "    builder=build_rf,\n",
    "    feature_type=\"TF-IDF → 200-d SVD\",\n",
    "    notes=\"Random forest on dense SVD vectors\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62504ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD + GradientBoosting: RMSE=156.003, R2=-0.015, train_time=2422.55s\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "def build_gbr():\n",
    "    return GradientBoostingRegressor(\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=500,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.9,\n",
    "    )\n",
    "\n",
    "evaluate_model(\n",
    "    name=\"SVD + GradientBoosting\",\n",
    "    feature_key=\"svd\",\n",
    "    target_key=\"raw\",\n",
    "    builder=build_gbr,\n",
    "    feature_type=\"TF-IDF → 200-d SVD\",\n",
    "    notes=\"Gradient boosting regressor on SVD features\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cdaf71",
   "metadata": {},
   "source": [
    "## MLPRegressor on SVD Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a29311f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD + MLP (raw): RMSE=150.232, R2=0.058, train_time=16.07s\n"
     ]
    }
   ],
   "source": [
    "def build_svd_mlp(alpha: float = 1e-4):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"mlp\", MLPRegressor(\n",
    "            hidden_layer_sizes=(128, 64),\n",
    "            activation=\"relu\",\n",
    "            alpha=alpha,\n",
    "            batch_size=256,\n",
    "            learning_rate_init=1e-3,\n",
    "            max_iter=200,\n",
    "            early_stopping=True,\n",
    "            n_iter_no_change=10,\n",
    "            random_state=RANDOM_STATE,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "# Raw target\n",
    "evaluate_model(\n",
    "    name=\"SVD + MLP (raw)\",\n",
    "    feature_key=\"svd\",\n",
    "    target_key=\"raw\",\n",
    "    builder=lambda: build_svd_mlp(alpha=1e-4),\n",
    "    feature_type=\"TF-IDF → 200-d SVD\",\n",
    "    notes=\"Two-layer MLP on SVD vectors\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e63ee72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD + MLP (log): RMSE=155.398, R2=-0.008, train_time=10.84s\n"
     ]
    }
   ],
   "source": [
    "# Log target\n",
    "evaluate_model(\n",
    "    name=\"SVD + MLP (log)\",\n",
    "    feature_key=\"svd\",\n",
    "    target_key=\"log\",\n",
    "    builder=lambda: build_svd_mlp(alpha=5e-5),\n",
    "    feature_type=\"TF-IDF → 200-d SVD\",\n",
    "    notes=\"Two-layer MLP predicting log scores\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e005ea",
   "metadata": {},
   "source": [
    "## Document Embeddings → Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59588df4",
   "metadata": {},
   "source": [
    "## Simple Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7e2dec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               model_name        feature_type   target_type       val_MSE  \\\n",
      "0         SVD + MLP (raw)  TF-IDF → 200-d SVD     raw score  22569.661099   \n",
      "1             SVD + Ridge  TF-IDF → 200-d SVD     raw score  23223.469624   \n",
      "2      SVD + RandomForest  TF-IDF → 200-d SVD     raw score  24017.792613   \n",
      "3         SVD + MLP (log)  TF-IDF → 200-d SVD  log1p(score)  24148.557882   \n",
      "4  SVD + GradientBoosting  TF-IDF → 200-d SVD     raw score  24336.808299   \n",
      "\n",
      "     val_RMSE    val_MAE    val_R2  training_time_sec  \\\n",
      "0  150.232024  31.667474  0.058267          16.066344   \n",
      "1  152.392485  41.161424  0.030986           0.253964   \n",
      "2  154.976749  35.266423 -0.002157        1316.229247   \n",
      "3  155.398063  20.483820 -0.007614          10.836792   \n",
      "4  156.002591  34.606112 -0.015468        2422.552881   \n",
      "\n",
      "                                         notes  \n",
      "0                 Two-layer MLP on SVD vectors  \n",
      "1                Dense LSA features with Ridge  \n",
      "2           Random forest on dense SVD vectors  \n",
      "3          Two-layer MLP predicting log scores  \n",
      "4  Gradient boosting regressor on SVD features  \n",
      "Ensembling models: ['SVD + MLP (raw)', 'SVD + Ridge', 'SVD + RandomForest']\n",
      "Mean Ensemble: RMSE=149.251, R2=0.071\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).sort_values('val_RMSE').reset_index(drop=True)\n",
    "print(results_df.head())\n",
    "\n",
    "ensemble_members = results_df.nsmallest(3, 'val_RMSE')['model_name'].tolist()\n",
    "print(f\"Ensembling models: {ensemble_members}\")\n",
    "\n",
    "val_preds = np.column_stack([val_predictions_store[name] for name in ensemble_members])\n",
    "ensemble_val_pred = val_preds.mean(axis=1)\n",
    "ensemble_metrics = regression_metrics(y_val, ensemble_val_pred)\n",
    "register_result(\n",
    "    name=\"Mean Ensemble\",\n",
    "    feature_type=\"Averaged predictions\",\n",
    "    target_key=\"raw\",\n",
    "    metrics=ensemble_metrics,\n",
    "    notes=f\"Mean of {ensemble_members}\",\n",
    ")\n",
    "val_predictions_store[\"Mean Ensemble\"] = ensemble_val_pred\n",
    "print(f\"Mean Ensemble: RMSE={ensemble_metrics['RMSE']:.3f}, R2={ensemble_metrics['R2']:.3f}\")\n",
    "model_registry[\"Mean Ensemble\"] = {\n",
    "    \"ensemble_members\": ensemble_members,\n",
    "    \"feature_type\": \"Averaged predictions\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3885c53f",
   "metadata": {},
   "source": [
    "## Validation Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea06ca3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>feature_type</th>\n",
       "      <th>target_type</th>\n",
       "      <th>val_MSE</th>\n",
       "      <th>val_RMSE</th>\n",
       "      <th>val_MAE</th>\n",
       "      <th>val_R2</th>\n",
       "      <th>training_time_sec</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean Ensemble</td>\n",
       "      <td>Averaged predictions</td>\n",
       "      <td>raw score</td>\n",
       "      <td>22275.854772</td>\n",
       "      <td>149.250979</td>\n",
       "      <td>32.882758</td>\n",
       "      <td>0.070526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mean of ['SVD + MLP (raw)', 'SVD + Ridge', 'SVD + RandomForest']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVD + MLP (raw)</td>\n",
       "      <td>TF-IDF → 200-d SVD</td>\n",
       "      <td>raw score</td>\n",
       "      <td>22569.661099</td>\n",
       "      <td>150.232024</td>\n",
       "      <td>31.667474</td>\n",
       "      <td>0.058267</td>\n",
       "      <td>16.066344</td>\n",
       "      <td>Two-layer MLP on SVD vectors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVD + Ridge</td>\n",
       "      <td>TF-IDF → 200-d SVD</td>\n",
       "      <td>raw score</td>\n",
       "      <td>23223.469624</td>\n",
       "      <td>152.392485</td>\n",
       "      <td>41.161424</td>\n",
       "      <td>0.030986</td>\n",
       "      <td>0.253964</td>\n",
       "      <td>Dense LSA features with Ridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVD + RandomForest</td>\n",
       "      <td>TF-IDF → 200-d SVD</td>\n",
       "      <td>raw score</td>\n",
       "      <td>24017.792613</td>\n",
       "      <td>154.976749</td>\n",
       "      <td>35.266423</td>\n",
       "      <td>-0.002157</td>\n",
       "      <td>1316.229247</td>\n",
       "      <td>Random forest on dense SVD vectors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVD + MLP (log)</td>\n",
       "      <td>TF-IDF → 200-d SVD</td>\n",
       "      <td>log1p(score)</td>\n",
       "      <td>24148.557882</td>\n",
       "      <td>155.398063</td>\n",
       "      <td>20.483820</td>\n",
       "      <td>-0.007614</td>\n",
       "      <td>10.836792</td>\n",
       "      <td>Two-layer MLP predicting log scores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVD + GradientBoosting</td>\n",
       "      <td>TF-IDF → 200-d SVD</td>\n",
       "      <td>raw score</td>\n",
       "      <td>24336.808299</td>\n",
       "      <td>156.002591</td>\n",
       "      <td>34.606112</td>\n",
       "      <td>-0.015468</td>\n",
       "      <td>2422.552881</td>\n",
       "      <td>Gradient boosting regressor on SVD features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGD Huber (raw)</td>\n",
       "      <td>TF-IDF (sparse)</td>\n",
       "      <td>raw score</td>\n",
       "      <td>24948.288150</td>\n",
       "      <td>157.950271</td>\n",
       "      <td>33.287046</td>\n",
       "      <td>-0.040983</td>\n",
       "      <td>28.655761</td>\n",
       "      <td>Huber regression with SGD on raw scores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearSVR (raw)</td>\n",
       "      <td>TF-IDF (sparse)</td>\n",
       "      <td>raw score</td>\n",
       "      <td>25077.202775</td>\n",
       "      <td>158.357831</td>\n",
       "      <td>31.997622</td>\n",
       "      <td>-0.046362</td>\n",
       "      <td>138.358618</td>\n",
       "      <td>LinearSVR predicting raw scores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearSVR (log)</td>\n",
       "      <td>TF-IDF (sparse)</td>\n",
       "      <td>log1p(score)</td>\n",
       "      <td>34211.311476</td>\n",
       "      <td>184.963000</td>\n",
       "      <td>53.387510</td>\n",
       "      <td>-0.427488</td>\n",
       "      <td>179.162760</td>\n",
       "      <td>LinearSVR trained on log1p scores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SGD Huber (log)</td>\n",
       "      <td>TF-IDF (sparse)</td>\n",
       "      <td>log1p(score)</td>\n",
       "      <td>70551.152332</td>\n",
       "      <td>265.614669</td>\n",
       "      <td>147.860321</td>\n",
       "      <td>-1.943791</td>\n",
       "      <td>26.368483</td>\n",
       "      <td>Huber regression with SGD on log scores</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_name          feature_type   target_type       val_MSE  \\\n",
       "0           Mean Ensemble  Averaged predictions     raw score  22275.854772   \n",
       "1         SVD + MLP (raw)    TF-IDF → 200-d SVD     raw score  22569.661099   \n",
       "2             SVD + Ridge    TF-IDF → 200-d SVD     raw score  23223.469624   \n",
       "3      SVD + RandomForest    TF-IDF → 200-d SVD     raw score  24017.792613   \n",
       "4         SVD + MLP (log)    TF-IDF → 200-d SVD  log1p(score)  24148.557882   \n",
       "5  SVD + GradientBoosting    TF-IDF → 200-d SVD     raw score  24336.808299   \n",
       "6         SGD Huber (raw)       TF-IDF (sparse)     raw score  24948.288150   \n",
       "7         LinearSVR (raw)       TF-IDF (sparse)     raw score  25077.202775   \n",
       "8         LinearSVR (log)       TF-IDF (sparse)  log1p(score)  34211.311476   \n",
       "9         SGD Huber (log)       TF-IDF (sparse)  log1p(score)  70551.152332   \n",
       "\n",
       "     val_RMSE     val_MAE    val_R2  training_time_sec  \\\n",
       "0  149.250979   32.882758  0.070526                NaN   \n",
       "1  150.232024   31.667474  0.058267          16.066344   \n",
       "2  152.392485   41.161424  0.030986           0.253964   \n",
       "3  154.976749   35.266423 -0.002157        1316.229247   \n",
       "4  155.398063   20.483820 -0.007614          10.836792   \n",
       "5  156.002591   34.606112 -0.015468        2422.552881   \n",
       "6  157.950271   33.287046 -0.040983          28.655761   \n",
       "7  158.357831   31.997622 -0.046362         138.358618   \n",
       "8  184.963000   53.387510 -0.427488         179.162760   \n",
       "9  265.614669  147.860321 -1.943791          26.368483   \n",
       "\n",
       "                                                              notes  \n",
       "0  Mean of ['SVD + MLP (raw)', 'SVD + Ridge', 'SVD + RandomForest']  \n",
       "1                                      Two-layer MLP on SVD vectors  \n",
       "2                                     Dense LSA features with Ridge  \n",
       "3                                Random forest on dense SVD vectors  \n",
       "4                               Two-layer MLP predicting log scores  \n",
       "5                       Gradient boosting regressor on SVD features  \n",
       "6                           Huber regression with SGD on raw scores  \n",
       "7                                   LinearSVR predicting raw scores  \n",
       "8                                 LinearSVR trained on log1p scores  \n",
       "9                           Huber regression with SGD on log scores  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).sort_values('val_RMSE').reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7624a6",
   "metadata": {},
   "source": [
    "## Final Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1def8e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomasz.makowski.2\\Desktop\\SemesterII\\AdvancedDataMining\\adm-stack-inference\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tomasz.makowski.2\\Desktop\\SemesterII\\AdvancedDataMining\\adm-stack-inference\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def predict_with_model(name: str, train_split: str, predict_split: str):\n",
    "    spec = model_registry[name]\n",
    "    if \"ensemble_members\" in spec:\n",
    "        member_preds = [\n",
    "            predict_with_model(member, train_split, predict_split)[1]\n",
    "            for member in spec[\"ensemble_members\"]\n",
    "        ]\n",
    "        stacked = np.column_stack(member_preds)\n",
    "        return None, stacked.mean(axis=1)\n",
    "\n",
    "    builder = spec[\"builder\"]\n",
    "    feature_key = spec[\"feature_key\"]\n",
    "    target_key = spec[\"target_key\"]\n",
    "    model = builder()\n",
    "    X_train_split = feature_store[feature_key][train_split]\n",
    "    X_predict = feature_store[feature_key][predict_split]\n",
    "    y_train_split = target_store[target_key][train_split]\n",
    "    model.fit(X_train_split, y_train_split)\n",
    "    preds_target = model.predict(X_predict)\n",
    "    preds_raw = inverse_target(target_key, preds_target)\n",
    "    return model, preds_raw\n",
    "\n",
    "final_candidates = results_df['model_name'].tolist()\n",
    "final_rows = []\n",
    "\n",
    "for name in final_candidates:\n",
    "    _, test_preds = predict_with_model(name, train_split=\"train_val\", predict_split=\"test\")\n",
    "    metrics = regression_metrics(y_test, test_preds)\n",
    "    val_row = results_df[results_df['model_name'] == name].iloc[0]\n",
    "    final_rows.append({\n",
    "        \"model_name\": name,\n",
    "        \"feature_type\": val_row[\"feature_type\"],\n",
    "        \"target_type\": val_row[\"target_type\"],\n",
    "        \"val_RMSE\": val_row[\"val_RMSE\"],\n",
    "        \"val_R2\": val_row[\"val_R2\"],\n",
    "        \"test_MSE\": metrics[\"MSE\"],\n",
    "        \"test_RMSE\": metrics[\"RMSE\"],\n",
    "        \"test_MAE\": metrics[\"MAE\"],\n",
    "        \"test_R2\": metrics[\"R2\"],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfaa6a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>feature_type</th>\n",
       "      <th>target_type</th>\n",
       "      <th>val_RMSE</th>\n",
       "      <th>val_R2</th>\n",
       "      <th>test_MSE</th>\n",
       "      <th>test_RMSE</th>\n",
       "      <th>test_MAE</th>\n",
       "      <th>test_R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVD + Ridge</td>\n",
       "      <td>TF-IDF → 200-d SVD</td>\n",
       "      <td>raw score</td>\n",
       "      <td>152.392485</td>\n",
       "      <td>0.030986</td>\n",
       "      <td>75692.079954</td>\n",
       "      <td>275.121937</td>\n",
       "      <td>42.580632</td>\n",
       "      <td>0.006925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mean Ensemble</td>\n",
       "      <td>Averaged predictions</td>\n",
       "      <td>raw score</td>\n",
       "      <td>149.250979</td>\n",
       "      <td>0.070526</td>\n",
       "      <td>75819.440525</td>\n",
       "      <td>275.353301</td>\n",
       "      <td>35.866879</td>\n",
       "      <td>0.005254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVD + MLP (log)</td>\n",
       "      <td>TF-IDF → 200-d SVD</td>\n",
       "      <td>log1p(score)</td>\n",
       "      <td>155.398063</td>\n",
       "      <td>-0.007614</td>\n",
       "      <td>76408.202611</td>\n",
       "      <td>276.420337</td>\n",
       "      <td>22.932554</td>\n",
       "      <td>-0.002471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGD Huber (raw)</td>\n",
       "      <td>TF-IDF (sparse)</td>\n",
       "      <td>raw score</td>\n",
       "      <td>157.950271</td>\n",
       "      <td>-0.040983</td>\n",
       "      <td>76846.048946</td>\n",
       "      <td>277.211199</td>\n",
       "      <td>31.265185</td>\n",
       "      <td>-0.008215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearSVR (raw)</td>\n",
       "      <td>TF-IDF (sparse)</td>\n",
       "      <td>raw score</td>\n",
       "      <td>158.357831</td>\n",
       "      <td>-0.046362</td>\n",
       "      <td>76861.438384</td>\n",
       "      <td>277.238955</td>\n",
       "      <td>28.378842</td>\n",
       "      <td>-0.008417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVD + RandomForest</td>\n",
       "      <td>TF-IDF → 200-d SVD</td>\n",
       "      <td>raw score</td>\n",
       "      <td>154.976749</td>\n",
       "      <td>-0.002157</td>\n",
       "      <td>77656.747041</td>\n",
       "      <td>278.669602</td>\n",
       "      <td>37.512205</td>\n",
       "      <td>-0.018851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVD + MLP (raw)</td>\n",
       "      <td>TF-IDF → 200-d SVD</td>\n",
       "      <td>raw score</td>\n",
       "      <td>150.232024</td>\n",
       "      <td>0.058267</td>\n",
       "      <td>78339.495774</td>\n",
       "      <td>279.891936</td>\n",
       "      <td>35.748540</td>\n",
       "      <td>-0.027809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVD + GradientBoosting</td>\n",
       "      <td>TF-IDF → 200-d SVD</td>\n",
       "      <td>raw score</td>\n",
       "      <td>156.002591</td>\n",
       "      <td>-0.015468</td>\n",
       "      <td>78928.498803</td>\n",
       "      <td>280.942163</td>\n",
       "      <td>37.424328</td>\n",
       "      <td>-0.035537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearSVR (log)</td>\n",
       "      <td>TF-IDF (sparse)</td>\n",
       "      <td>log1p(score)</td>\n",
       "      <td>184.963000</td>\n",
       "      <td>-0.427488</td>\n",
       "      <td>81815.923707</td>\n",
       "      <td>286.034830</td>\n",
       "      <td>42.515413</td>\n",
       "      <td>-0.073419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SGD Huber (log)</td>\n",
       "      <td>TF-IDF (sparse)</td>\n",
       "      <td>log1p(score)</td>\n",
       "      <td>265.614669</td>\n",
       "      <td>-1.943791</td>\n",
       "      <td>123119.494553</td>\n",
       "      <td>350.883876</td>\n",
       "      <td>151.637920</td>\n",
       "      <td>-0.615320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_name          feature_type   target_type    val_RMSE  \\\n",
       "0             SVD + Ridge    TF-IDF → 200-d SVD     raw score  152.392485   \n",
       "1           Mean Ensemble  Averaged predictions     raw score  149.250979   \n",
       "2         SVD + MLP (log)    TF-IDF → 200-d SVD  log1p(score)  155.398063   \n",
       "3         SGD Huber (raw)       TF-IDF (sparse)     raw score  157.950271   \n",
       "4         LinearSVR (raw)       TF-IDF (sparse)     raw score  158.357831   \n",
       "5      SVD + RandomForest    TF-IDF → 200-d SVD     raw score  154.976749   \n",
       "6         SVD + MLP (raw)    TF-IDF → 200-d SVD     raw score  150.232024   \n",
       "7  SVD + GradientBoosting    TF-IDF → 200-d SVD     raw score  156.002591   \n",
       "8         LinearSVR (log)       TF-IDF (sparse)  log1p(score)  184.963000   \n",
       "9         SGD Huber (log)       TF-IDF (sparse)  log1p(score)  265.614669   \n",
       "\n",
       "     val_R2       test_MSE   test_RMSE    test_MAE   test_R2  \n",
       "0  0.030986   75692.079954  275.121937   42.580632  0.006925  \n",
       "1  0.070526   75819.440525  275.353301   35.866879  0.005254  \n",
       "2 -0.007614   76408.202611  276.420337   22.932554 -0.002471  \n",
       "3 -0.040983   76846.048946  277.211199   31.265185 -0.008215  \n",
       "4 -0.046362   76861.438384  277.238955   28.378842 -0.008417  \n",
       "5 -0.002157   77656.747041  278.669602   37.512205 -0.018851  \n",
       "6  0.058267   78339.495774  279.891936   35.748540 -0.027809  \n",
       "7 -0.015468   78928.498803  280.942163   37.424328 -0.035537  \n",
       "8 -0.427488   81815.923707  286.034830   42.515413 -0.073419  \n",
       "9 -1.943791  123119.494553  350.883876  151.637920 -0.615320  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results_df = pd.DataFrame(final_rows).sort_values('test_RMSE').reset_index(drop=True)\n",
    "final_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advanced-data-mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
